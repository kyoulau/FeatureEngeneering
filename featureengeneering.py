# -*- coding: utf-8 -*-
"""FeatureEngeneering.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1x5fHNXvtvZHI-3LjiyldxsK2F5ZjhrNP
"""

import tensorflow as tf
from tensorflow.keras import datasets, layers, models
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()

x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

# Image redimension for CNN
x_train = x_train.reshape((60000, 28, 28, 1))
x_test = x_test.reshape((10000, 28, 28, 1))

# Split the set between training and validation
x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=42) # 25% validation

# Adjusting proportions
x_train, x_temp, y_train, y_temp = train_test_split(x_train, y_train, test_size=1/3, random_state=42)
x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5, random_state=42)

print("TRAINING SET:", x_train.shape, y_train.shape)
print("VALIDATION SET:", x_val.shape, y_val.shape)
print("TEST SET:", x_test.shape, y_test.shape)

"""**x_train, y_train**: Conjuntos para treinar modelo de rede neural.
<br>
**x_val, y_val**: Conjuntos para monitorar o desempenho do modelo durante o treinamento e ajustar os hiperparâmetros.
<br>
**x_test, y_test**: Conjuntos para avaliar o desempenho final do modelo após o treinamento.
"""

# LeNet-5
model = models.Sequential([
    layers.Conv2D(6, kernel_size=(5, 5), activation='relu', input_shape=(28, 28, 1)),
    layers.MaxPooling2D(pool_size=(2, 2)),
    layers.Conv2D(16, kernel_size=(5, 5), activation='relu'),
    layers.MaxPooling2D(pool_size=(2, 2)),
    layers.Flatten(),
    layers.Dense(120, activation='relu'),
    layers.Dense(84, activation='relu'),
    layers.Dense(10, activation='softmax')
])

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Train the model
history = model.fit(x_train, y_train, epochs=10,
                    validation_data=(x_val, y_val))

# Avaliate the model
test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)
print(f'Precisão do teste: {test_acc}')

# generate the matrix
y_pred = model.predict(x_test)
y_pred_classes = np.argmax(y_pred, axis=1)
conf_matrix = confusion_matrix(y_test, y_pred_classes)

# Visualize the matrix
plt.figure(figsize=(10, 8))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Previsões')
plt.ylabel('Rótulos Verdadeiros')
plt.title('Matriz de Confusão')
plt.show()